{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5705fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EMOTION CLASSIFICATION - FULL DATASET\n",
      "================================================================================\n",
      "✓ Loaded dataset: 106,963 posts\n",
      "✓ Using Apple Silicon GPU (MPS)\n",
      "✓ Loaded 28 emotion labels\n",
      "✓ Loading model from: ./mentalbert-goemotions-final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully\n",
      "\n",
      "⚙️  Preparing text...\n",
      "✓ 106,963 posts with valid text\n",
      "\n",
      "================================================================================\n",
      "PROCESSING ALL POSTS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying emotions:  29%|██▉       | 31139/106963 [1:31:05<6:06:00,  3.45it/s] "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EMOTION CLASSIFICATION - FULL DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD DATASET\n",
    "# ============================================================================\n",
    "\n",
    "df = pd.read_csv(\"reddit_posts_finance_labeled_cleaned.csv\")\n",
    "print(f\"✓ Loaded dataset: {len(df):,} posts\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SETUP DEVICE\n",
    "# ============================================================================\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 0  # MPS\n",
    "    print(\"✓ Using Apple Silicon GPU (MPS)\")\n",
    "else:\n",
    "    device = -1  # CPU\n",
    "    print(\"⚠️ MPS not available, using CPU\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. LOAD EMOTION LABELS\n",
    "# ============================================================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "emotion_labels = dataset[\"train\"].features[\"labels\"].feature.names\n",
    "\n",
    "print(f\"✓ Loaded {len(emotion_labels)} emotion labels\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. LOAD MODEL\n",
    "# ============================================================================\n",
    "\n",
    "model_path = \"./mentalbert-goemotions-final\"\n",
    "print(f\"✓ Loading model from: {model_path}\")\n",
    "\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    device=device,\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "print(\"✓ Model loaded successfully\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. PREPARE TEXT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n⚙️  Preparing text...\")\n",
    "df['combined_text'] = df['title'].fillna('') + ' ' + df['text'].fillna('')\n",
    "\n",
    "# Remove empty posts\n",
    "df = df[df['combined_text'].str.strip().str.len() > 0].copy()\n",
    "print(f\"✓ {len(df):,} posts with valid text\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. EMOTION CLASSIFICATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def get_emotion_scores(text, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Get emotions above threshold for a text.\n",
    "    Returns dict of {emotion_name: score}\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        full_text = str(text)[:512]  # Truncate to 512 chars\n",
    "        results = emotion_classifier(full_text)[0]\n",
    "        \n",
    "        emotions = {}\n",
    "        for r in results:\n",
    "            label_idx = int(r['label'].split('_')[1])\n",
    "            emotion_name = emotion_labels[label_idx]\n",
    "            score = r['score']\n",
    "            \n",
    "            if score > threshold:\n",
    "                emotions[emotion_name] = round(score, 4)\n",
    "        \n",
    "        return emotions\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)[:50]}\")\n",
    "        return {}\n",
    "\n",
    "# ============================================================================\n",
    "# 7. PROCESS ALL POSTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING ALL POSTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Process with progress bar\n",
    "tqdm.pandas(desc=\"Classifying emotions\")\n",
    "df['emotions'] = df['combined_text'].progress_apply(get_emotion_scores)\n",
    "\n",
    "print(f\"\\n✓ Processed {len(df):,} posts\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. EXTRACT TOP EMOTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n⚙️  Extracting top emotions...\")\n",
    "\n",
    "def get_top_emotion(emotion_dict):\n",
    "    if not emotion_dict or len(emotion_dict) == 0:\n",
    "        return ('none', 0.0)\n",
    "    top = max(emotion_dict.items(), key=lambda x: x[1])\n",
    "    return top\n",
    "\n",
    "df[['top_emotion', 'top_emotion_score']] = df['emotions'].apply(\n",
    "    lambda x: pd.Series(get_top_emotion(x))\n",
    ")\n",
    "\n",
    "print(\"✓ Top emotions extracted\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. CREATE INDIVIDUAL EMOTION COLUMNS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n⚙️  Creating individual emotion columns...\")\n",
    "\n",
    "for emotion in emotion_labels:\n",
    "    df[f'emotion_{emotion}'] = df['emotions'].apply(\n",
    "        lambda x: x.get(emotion, 0.0) if isinstance(x, dict) else 0.0\n",
    "    )\n",
    "\n",
    "print(f\"✓ Created {len(emotion_labels)} emotion score columns\")\n",
    "\n",
    "# Count emotions per post\n",
    "df['num_emotions'] = df['emotions'].apply(\n",
    "    lambda x: len(x) if isinstance(x, dict) else 0\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 15 Most Common Emotions (as primary emotion):\")\n",
    "top_emotions = df['top_emotion'].value_counts().head(15)\n",
    "for emotion, count in top_emotions.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {emotion:15s}: {count:6,} ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\nTop 15 Emotions by Average Score Across All Posts:\")\n",
    "emotion_cols = [col for col in df.columns if col.startswith('emotion_')]\n",
    "avg_scores = df[emotion_cols].mean().sort_values(ascending=False).head(15)\n",
    "for col, score in avg_scores.items():\n",
    "    emotion = col.replace('emotion_', '')\n",
    "    print(f\"  {emotion:15s}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nEmotion Co-occurrence:\")\n",
    "print(f\"  Posts with 0 emotions: {(df['num_emotions'] == 0).sum():,}\")\n",
    "print(f\"  Posts with 1 emotion:  {(df['num_emotions'] == 1).sum():,}\")\n",
    "print(f\"  Posts with 2 emotions: {(df['num_emotions'] == 2).sum():,}\")\n",
    "print(f\"  Posts with 3+ emotions: {(df['num_emotions'] >= 3).sum():,}\")\n",
    "print(f\"  Average emotions/post: {df['num_emotions'].mean():.2f}\")\n",
    "print(f\"  Max emotions in a post: {df['num_emotions'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. FINANCE vs NON-FINANCE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINANCE vs NON-FINANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "finance_posts = df[df['finance_label'] == 'finance']\n",
    "non_finance_posts = df[df['finance_label'] == 'not finance']\n",
    "\n",
    "print(f\"\\nFinance posts: {len(finance_posts):,}\")\n",
    "print(f\"Non-finance posts: {len(non_finance_posts):,}\")\n",
    "\n",
    "if len(finance_posts) > 0:\n",
    "    print(\"\\nTop 10 emotions in FINANCE posts:\")\n",
    "    for emotion, count in finance_posts['top_emotion'].value_counts().head(10).items():\n",
    "        pct = (count / len(finance_posts)) * 100\n",
    "        print(f\"  {emotion:15s}: {count:5,} ({pct:5.2f}%)\")\n",
    "\n",
    "if len(non_finance_posts) > 0:\n",
    "    print(\"\\nTop 10 emotions in NON-FINANCE posts:\")\n",
    "    for emotion, count in non_finance_posts['top_emotion'].value_counts().head(10).items():\n",
    "        pct = (count / len(non_finance_posts)) * 100\n",
    "        print(f\"  {emotion:15s}: {count:5,} ({pct:5.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 12. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Full dataset with all columns\n",
    "output_full = \"reddit_with_emotions_full.csv\"\n",
    "df.to_csv(output_full, index=False)\n",
    "print(f\"✓ Full dataset saved: {output_full}\")\n",
    "print(f\"  Size: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "\n",
    "# Summary version (without individual emotion columns)\n",
    "summary_cols = ['author', 'title', 'score', 'created', 'link', 'text', \n",
    "                'year', 'year_month', 'finance_label', 'finance_score',\n",
    "                'emotions', 'top_emotion', 'top_emotion_score', 'num_emotions']\n",
    "summary_cols = [col for col in summary_cols if col in df.columns]\n",
    "\n",
    "output_summary = \"reddit_emotions_summary.csv\"\n",
    "df[summary_cols].to_csv(output_summary, index=False)\n",
    "print(f\"✓ Summary saved: {output_summary}\")\n",
    "print(f\"  Size: {len(df):,} rows, {len(summary_cols)} columns\")\n",
    "\n",
    "# ============================================================================\n",
    "# 13. SAMPLE OUTPUT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RESULTS (First 5 Posts)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx in range(min(5, len(df))):\n",
    "    row = df.iloc[idx]\n",
    "    print(f\"\\n--- Post {idx+1} ---\")\n",
    "    print(f\"Title: {row['title'][:80]}...\")\n",
    "    print(f\"Finance: {row['finance_label']}\")\n",
    "    print(f\"Top emotion: {row['top_emotion']} ({row['top_emotion_score']:.3f})\")\n",
    "    if len(row['emotions']) > 0:\n",
    "        print(f\"All emotions ({len(row['emotions'])}): {dict(list(row['emotions'].items())[:5])}...\")\n",
    "    else:\n",
    "        print(f\"All emotions: none detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal posts processed: {len(df):,}\")\n",
    "print(f\"\\nOutput files created:\")\n",
    "print(f\"  1. {output_full}\")\n",
    "print(f\"  2. {output_summary}\")\n",
    "print(\"\\nYou can now use these files for further analysis and visualization!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
